#!/usr/bin/env python3
# SPDX-License-Identifier: BSD-3-Clause
# Copyright <2025> <Uri Herrera <uri_herrera@nxos.org>>

import argparse
import os
import re
import subprocess
import sys
import tarfile


def load_package_list(file_path):
    """Load a dpkg-style package list file into a nameâ†’version mapping.

    The function expects the input file to contain lines like the output of
    `dpkg -l`, and only processes lines that start with ``ii``.

    Args:
        file_path: Path to the text file containing the package list.

    Returns:
        A dict mapping package names (without architecture suffix) to version
        strings.

    Raises:
        SystemExit: If the file does not exist or cannot be read.
    """
    if not os.path.exists(file_path):
        print(f"Error: The package list file '{file_path}' does not exist.")
        sys.exit(1)

    packages = {}
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            for line in file:
                if line.startswith("ii"):
                    parts = line.split()
                    if len(parts) >= 3:
                        package_name = parts[1].replace(":amd64", "")
                        package_version = parts[2]
                        packages[package_name] = package_version
    except PermissionError:
        print(f"Error: Permission denied reading '{file_path}'.")
        sys.exit(1)
    except Exception as e:
        print(f"Error reading '{file_path}': {e}")
        sys.exit(1)

    return packages


def compare_package_lists(list_a, list_b):
    """Compare two package lists and classify version changes and presence.

    Args:
        list_a: Dict mapping package names to versions for the reference list.
        list_b: Dict mapping package names to versions for the comparison list.

    Returns:
        A tuple of three lists:
            - Packages present in both lists with a different version in list_b.
            - Packages only present in list_b.
            - Packages present in list_a but not in list_b.
    """
    newer_versions = {}
    only_in_b = {}
    removed_packages = {}

    for package, version in list_b.items():
        if package in list_a:
            if version != list_a[package]:
                newer_versions[package] = version
        else:
            only_in_b[package] = version

    for package in list_a:
        if package not in list_b:
            removed_packages[package] = list_a[package]

    return list(newer_versions.keys()), list(only_in_b.keys()), list(removed_packages.keys())


def remove_excluded_packages(packages, exclude_list, exclude_patterns):
    """Filter out packages that match explicit names or regex patterns.

    Args:
        packages: Iterable of package names to filter.
        exclude_list: Iterable of package names to exclude directly.
        exclude_patterns: Iterable of regular expression patterns; any package
            whose name matches at least one of these patterns is excluded.

    Returns:
        A list containing only packages that are not excluded.
    """
    return [
        package
        for package in packages
        if package not in exclude_list
        and not any(re.search(pattern, package) for pattern in exclude_patterns)
    ]


def save_packages_to_file(packages, file_name):
    """Write a package list to a file, one package per line.

    Args:
        packages: Iterable of package names to write.
        file_name: Path to the output file.
    """
    with open(file_name, "w", encoding="utf-8") as file:
        for package in packages:
            file.write(f"{package}\n")


def _parse_relation_names(value):
    """Parse a Debian relation field into a set of package names.

    This processes fields such as ``Replaces`` or ``Provides``, handling
    comma-separated entries and ``|``-separated alternatives, stripping
    version constraints.

    Args:
        value: Raw string value of a relation field.

    Returns:
        A set of package names extracted from the relation field.
    """
    if not value:
        return set()

    value = value.replace("\n", " ")
    items = [v.strip() for v in value.split(",") if v.strip()]

    pkgs = set()
    for item in items:
        alts = [a.strip() for a in item.split("|") if a.strip()]
        for alt in alts:
            name = alt.split("(", maxsplit=1)[0].strip()
            if name:
                pkgs.add(name)
    return pkgs


def parse_dpkg_status_bytes(data):
    """Parse the contents of a dpkg status file into metadata for each package.

    The function extracts only the ``Package``, ``Replaces``, and ``Provides``
    fields from each stanza.

    Args:
        data: Raw byte string containing the contents of ``/var/lib/dpkg/status``.

    Returns:
        A dict mapping package names to a dict with keys ``Replaces`` and
        ``Provides``, each containing a set of package names.
    """
    text = data.decode("utf-8", errors="replace")
    stanzas = [s for s in text.split("\n\n") if s.strip()]
    meta = {}

    for stanza in stanzas:
        current_key = None
        fields = {}
        for line in stanza.splitlines():
            if not line:
                continue
            if line[0].isspace() and current_key:
                fields[current_key] = fields.get(current_key, "") + "\n" + line.strip()
                continue
            if ":" not in line:
                continue
            k, v = line.split(":", 1)
            current_key = k.strip()
            fields[current_key] = v.lstrip()

        pkg = fields.get("Package")
        if not pkg:
            continue

        replaces = _parse_relation_names(fields.get("Replaces", ""))
        provides = _parse_relation_names(fields.get("Provides", ""))

        meta[pkg] = {"Replaces": replaces, "Provides": provides}

    return meta


def load_dpkg_metadata_from_tar(tar_path):
    """Load dpkg status metadata from a tar archive containing /var/lib/dpkg.

    Args:
        tar_path: Path to the tar archive that holds the dpkg database.

    Returns:
        A dict in the same format as returned by ``parse_dpkg_status_bytes``.

    Raises:
        SystemExit: If the archive does not exist, is invalid, or does not
            contain the expected status file.
    """
    if not os.path.exists(tar_path):
        print(f"Error: The archive '{tar_path}' does not exist.")
        sys.exit(1)

    candidates = [
        "/var/lib/dpkg/status",
        "var/lib/dpkg/status",
        "./var/lib/dpkg/status",
    ]

    try:
        with tarfile.open(tar_path, "r:*") as tf:
            members = {m.name: m for m in tf.getmembers()}

            status_member = None
            for c in candidates:
                if c in members and members[c].isfile():
                    status_member = members[c]
                    break

            if status_member is None:
                print(f"Error: Could not find /var/lib/dpkg/status in '{tar_path}'.")
                sys.exit(1)

            f = tf.extractfile(status_member)
            if f is None:
                print(f"Error: Could not read /var/lib/dpkg/status from '{tar_path}'.")
                sys.exit(1)

            data = f.read()
            return parse_dpkg_status_bytes(data)

    except tarfile.ReadError:
        print(f"Error: '{tar_path}' is not a valid tar archive.")
        sys.exit(1)


def get_control_data_from_host(package_name):
    """Query dpkg on the host for Replaces/Provides metadata of a package.

    Args:
        package_name: Name of the package to query with ``dpkg-query``.

    Returns:
        A dict with keys ``Replaces`` and ``Provides``, each mapped to a set
        of package names. If the query fails, both sets are empty.
    """
    try:
        proc = subprocess.run(
            ["dpkg-query", "-W", "-f=${Replaces}\n${Provides}\n", package_name],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.DEVNULL,
            text=True,
        )
        lines = proc.stdout.splitlines()
        replaces_raw = lines[0].strip() if len(lines) >= 1 else ""
        provides_raw = lines[1].strip() if len(lines) >= 2 else ""
    except (FileNotFoundError, subprocess.CalledProcessError):
        replaces_raw = ""
        provides_raw = ""

    return {"Replaces": _parse_relation_names(replaces_raw), "Provides": _parse_relation_names(provides_raw)}


def build_transition_index_for_b(list_b, dpkg_meta_b):
    """Build reverse indexes of Replaces/Provides transitions for list B.

    The indexes map package names that are being replaced or provided to
    the packages in list B that perform those actions.

    Args:
        list_b: Dict mapping package names to versions for list B.
        dpkg_meta_b: Optional dict with dpkg metadata for list B packages,
            as produced by ``load_dpkg_metadata_from_tar``. If ``None``,
            metadata is queried from the host using ``dpkg-query``.

    Returns:
        A tuple ``(replaces_index, provides_index)`` where each index maps a
        package name to a set of package names from list B.
    """
    replaces_index = {}
    provides_index = {}

    for pkg in list_b.keys():
        if dpkg_meta_b is not None:
            md = dpkg_meta_b.get(pkg, {"Replaces": set(), "Provides": set()})
        else:
            md = get_control_data_from_host(pkg)

        for r in md.get("Replaces", set()):
            replaces_index.setdefault(r, set()).add(pkg)

        for p in md.get("Provides", set()):
            provides_index.setdefault(p, set()).add(pkg)

    return replaces_index, provides_index


def main():
    """Entry point for the pkg-compare CLI.

    Parses command-line arguments, loads the two package lists, evaluates
    updated, new, and removed packages, applies transition and exclusion
    rules, and writes the resulting lists to the requested output files.
    """
    parser = argparse.ArgumentParser(
        description="Compare two dpkg package lists.",
        formatter_class=argparse.RawTextHelpFormatter,
    )
    parser.add_argument(
        "-c",
        "--compare",
        nargs=2,
        metavar=("list1.txt", "list2.txt"),
        help="Paths to the package lists to compare, i.e., old_list1.txt new_list2.txt.",
    )
    parser.add_argument(
        "-u",
        "--out-updated",
        metavar="update_list.txt",
        help="File name for saving packages with newer versions.",
    )
    parser.add_argument(
        "-n",
        "--out-new",
        metavar="new_list.txt",
        help="File name for saving packages only in the second list.",
    )
    parser.add_argument(
        "-r",
        "--out-removed",
        metavar="removed_list.txt",
        help="File name for saving packages removed from the second list.",
    )
    parser.add_argument(
        "--dpkg-db-a",
        metavar="var-lib-dpkg-a.tar.xz",
        help="TAR archive containing /var/lib/dpkg from the rootfs snapshot used to generate list A.",
    )
    parser.add_argument(
        "--dpkg-db-b",
        metavar="var-lib-dpkg-b.tar.xz",
        help="TAR archive containing /var/lib/dpkg from the rootfs snapshot used to generate list B.",
    )

    args = parser.parse_args()

    exclude_list = [
        "apt-transport-https",
        "calamares",
        "calamares-qml-settings-nitrux",
        "casper",
    ]

    exclude_patterns = [
        r"nvidia",
        r"systemd",
    ]

    if args.compare and args.out_updated and args.out_new and args.out_removed:
        list_a = load_package_list(args.compare[0])
        list_b = load_package_list(args.compare[1])

        newer_versions, only_in_b, removed_packages = compare_package_lists(list_a, list_b)

        dpkg_meta_b = None
        if args.dpkg_db_b:
            dpkg_meta_b = load_dpkg_metadata_from_tar(args.dpkg_db_b)

        replaces_index, provides_index = build_transition_index_for_b(list_b, dpkg_meta_b)

        real_removals = []
        for removed_pkg in removed_packages:
            if removed_pkg in replaces_index or removed_pkg in provides_index:
                continue
            real_removals.append(removed_pkg)

        filtered_newer_versions = remove_excluded_packages(newer_versions, exclude_list, exclude_patterns)
        filtered_only_in_b = remove_excluded_packages(only_in_b, exclude_list, exclude_patterns)
        filtered_removed_packages = remove_excluded_packages(real_removals, exclude_list, exclude_patterns)

        save_packages_to_file(filtered_newer_versions, args.out_updated)
        save_packages_to_file(filtered_only_in_b, args.out_new)
        save_packages_to_file(filtered_removed_packages, args.out_removed)

        print(f"Updated packages are saved to {args.out_updated}")
        print(f"Newly added packages are saved to {args.out_new}")
        print(f"Removed packages are saved to {args.out_removed}")
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
